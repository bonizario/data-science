{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "all_data = pd.concat((\n",
    "    train.loc[:,'Pclass':],\n",
    "     test.loc[:,'Pclass':]))\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1309 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    1309 non-null   int64  \n",
      " 1   Name      1309 non-null   object \n",
      " 2   Sex       1309 non-null   object \n",
      " 3   Age       1046 non-null   float64\n",
      " 4   SibSp     1309 non-null   int64  \n",
      " 5   Parch     1309 non-null   int64  \n",
      " 6   Ticket    1309 non-null   object \n",
      " 7   Fare      1308 non-null   float64\n",
      " 8   Cabin     295 non-null    object \n",
      " 9   Embarked  1307 non-null   object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 112.5+ KB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pclass          Age        SibSp        Parch         Fare\n",
       "count  1309.000000  1046.000000  1309.000000  1309.000000  1308.000000\n",
       "mean      2.294882    29.881138     0.498854     0.385027    33.295479\n",
       "std       0.837836    14.413493     1.041658     0.865560    51.758668\n",
       "min       1.000000     0.170000     0.000000     0.000000     0.000000\n",
       "25%       2.000000    21.000000     0.000000     0.000000     7.895800\n",
       "50%       3.000000    28.000000     0.000000     0.000000    14.454200\n",
       "75%       3.000000    39.000000     1.000000     0.000000    31.275000\n",
       "max       3.000000    80.000000     8.000000     9.000000   512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PClass (apesar de numérico) -> dummies\n",
    "# Names -> *transformar em títulos* e dummies\n",
    "# Age -> preencher com média por grupos\n",
    "# Sex -> Dummies\n",
    "# SibSp e Parch -> transformar em tamanho da família\n",
    "# Ticket -> Manter só as letras\n",
    "# Fare -> preencher nulos com média\n",
    "# Cabin -> transformar em deck, preencher com moda (U) e dummies\n",
    "# Embarked -> preencher nulos com a moda e depois dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Title'] = all_data['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "title_map = {\n",
    "    'Capt':       'Officer',\n",
    "    'Col':        'Officer',\n",
    "    'Major':      'Officer',\n",
    "    'Jonkheer':   'Royalty',\n",
    "    'Don':        'Royalty',\n",
    "    'Sir' :       'Royalty',\n",
    "    'Dr':         'Officer',\n",
    "    'Rev':        'Officer',\n",
    "    'the Countess':'Royalty',\n",
    "    'Dona':       'Royalty',\n",
    "    'Mme':        'Mrs',\n",
    "    'Mlle':       'Miss',\n",
    "    'Ms':         'Mrs',\n",
    "    'Mr' :        'Mr',\n",
    "    'Mrs' :       'Mrs',\n",
    "    'Miss' :      'Miss',\n",
    "    'Master' :    'Master',\n",
    "    'Lady' :      'Royalty'\n",
    "}\n",
    "all_data['Title'] = all_data['Title'].map(title_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillAges(row):\n",
    "    if row['Sex']=='female' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 30\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 45\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 49\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return 39\n",
    "\n",
    "    elif row['Sex']=='female' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 20\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 30\n",
    "\n",
    "    elif row['Sex']=='female' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 18\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 31\n",
    "\n",
    "    elif row['Sex']=='male' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 41.5\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 52\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return 40\n",
    "\n",
    "    elif row['Sex']=='male' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 2\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 30\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 41.5\n",
    "\n",
    "    elif row['Sex']=='male' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 26\n",
    "all_data['Age'] = all_data.apply(lambda r : fillAges(r) if np.isnan(r['Age']) else r['Age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop('Name',axis=1,inplace=True)\n",
    "titles_dummies = pd.get_dummies(all_data['Title'], prefix='Title')\n",
    "all_data = pd.concat([all_data, titles_dummies],axis=1)\n",
    "all_data.drop('Title',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Sex'] = all_data['Sex'].map(lambda x: 1 if x == 'male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['FamilySize'] = all_data['Parch'] + all_data['SibSp'] + 1 # (+1 o próprio cara)\n",
    "# introducing other features based on the family size\n",
    "all_data['Singleton'] = all_data['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
    "all_data['SmallFamily'] = all_data['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
    "all_data['LargeFamily'] = all_data['FamilySize'].map(lambda s : 1 if 5<=s else 0)\n",
    "all_data.drop('SibSp', axis=1, inplace=True)\n",
    "all_data.drop('Parch', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Ticket'] = all_data['Ticket'].map(lambda x: ''.join(filter(str.isalpha, x)))\n",
    "all_data['Ticket'] = all_data['Ticket'].map(lambda x: x if x else 'XXX')\n",
    "tickets_dummies = pd.get_dummies(all_data['Ticket'],prefix='Ticket')\n",
    "all_data = pd.concat([all_data, tickets_dummies],axis=1)\n",
    "all_data.drop('Ticket',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_mean = all_data['Fare'].mean()\n",
    "all_data['Fare'] = all_data['Fare'].fillna(fare_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Cabin'] = all_data['Cabin'].fillna('U')\n",
    "all_data['Cabin'] = all_data['Cabin'].map(lambda x: x[0])\n",
    "cabin_dummies = pd.get_dummies(all_data['Cabin'],prefix='Cabin')\n",
    "all_data = pd.concat([all_data, cabin_dummies],axis=1)\n",
    "all_data.drop('Cabin',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mode = all_data['Embarked'].mode()\n",
    "all_data['Embarked'] = all_data['Embarked'].fillna(embarked_mode)\n",
    "embarked_dummies = pd.get_dummies(all_data['Embarked'],prefix='Embarked')\n",
    "all_data = pd.concat([all_data, embarked_dummies],axis=1)\n",
    "all_data.drop('Embarked',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(x+1) nas features númericas para obter distribuição de frequência mais próxima da normal\n",
    "\n",
    "# selecionando features numéricas\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != 'object'].index\n",
    "# calculando skew (assimetria)\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "# filtro por skew maior que 0.75 (perto de zero é normal)\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "# selecionando índices para normalização\n",
    "skewed_feats = skewed_feats.index\n",
    "# normalizando por log(x + 1)\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# ajusta o método aos dados\n",
    "scaler.fit(all_data)\n",
    "# transforma os dados\n",
    "X = scaler.transform(all_data)\n",
    "# sobrescreve o Data Frame\n",
    "all_data = pd.DataFrame(X, columns=all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data[:train.shape[0]]\n",
    "test = all_data[train.shape[0]:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instances = [\n",
    "    (RandomForestClassifier(), 'RandomForestClassifier'),\n",
    "    (ExtraTreesClassifier(), 'ExtraTreesClassifier'),\n",
    "    (GradientBoostingClassifier(), 'GradientBoostingClassifier'),\n",
    "    (LogisticRegression(), 'LogisticRegression'),\n",
    "    (DecisionTreeClassifier(), 'DecisionTreeClassifier'),\n",
    "    (KNeighborsClassifier(), 'KNeighborsClassifier'),\n",
    "    (GaussianNB(), 'GaussianNB'),\n",
    "    (Perceptron(), 'Perceptron'),\n",
    "    (SGDClassifier(), 'SGDClassifier'),\n",
    "    (SVC(), 'SVC'),\n",
    "    (LinearSVC(), 'LinearSVC'),\n",
    "    (LGBMClassifier(verbose=0), 'LGBMClassifier'),\n",
    "    (XGBClassifier(), 'XGBClassifier'),\n",
    "    (CatBoostClassifier(verbose=False), 'CatBoostClassifier'), \n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'Model':[],\n",
    "    'ACC':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "for model, model_name in model_instances:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results['Model'].append(model_name)\n",
    "    results['ACC'].append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.825112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.825112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.793722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.825112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.816143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.820628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.461883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.798206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.820628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.829596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.825112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.798206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.816143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.834081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model       ACC\n",
       "0       RandomForestClassifier  0.825112\n",
       "1         ExtraTreesClassifier  0.825112\n",
       "2   GradientBoostingClassifier  0.793722\n",
       "3           LogisticRegression  0.825112\n",
       "4       DecisionTreeClassifier  0.816143\n",
       "5         KNeighborsClassifier  0.820628\n",
       "6                   GaussianNB  0.461883\n",
       "7                   Perceptron  0.798206\n",
       "8                SGDClassifier  0.820628\n",
       "9                          SVC  0.829596\n",
       "10                   LinearSVC  0.825112\n",
       "11              LGBMClassifier  0.798206\n",
       "12               XGBClassifier  0.816143\n",
       "13          CatBoostClassifier  0.834081"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13        CatBoostClassifier\n",
       "9                        SVC\n",
       "0     RandomForestClassifier\n",
       "1       ExtraTreesClassifier\n",
       "3         LogisticRegression\n",
       "Name: Model, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_temp = results.sort_values('ACC', ascending=False)\n",
    "results_temp.iloc[:5]['Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.8295964125560538\n",
      "200 0.8340807174887892\n",
      "300 0.8295964125560538\n",
      "500 0.8340807174887892\n",
      "1000 0.8295964125560538\n"
     ]
    }
   ],
   "source": [
    "for n in [100,200,300,500,1000]:\n",
    "    model = RandomForestClassifier(n_estimators=n)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(n, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8398720682302772\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Escolha dos melhores parâmetros\n",
    "randomForest = RandomForestClassifier()\n",
    "cross_validation = StratifiedKFold(n_splits=5) # n_folds deve ser escolhido de forma precisa\n",
    "parameter_grid = {\n",
    "     'max_depth' : [10,20,30],\n",
    "     'n_estimators': [100, 300,500],\n",
    "     'criterion': ['gini','entropy',],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    randomForest,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=500, # tunado\n",
    "    criterion='entropy', # tunado\n",
    "    max_depth=10, # tunado\n",
    ")\n",
    "\n",
    "random_forest.fit(X, y)\n",
    "y_pred = random_forest.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv',index_col=0)\n",
    "sample_submission['Survived'] = y_pred\n",
    "sample_submission.to_csv('random_forest_tunado.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
