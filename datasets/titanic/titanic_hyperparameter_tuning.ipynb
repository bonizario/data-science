{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "all_data = pd.concat((\n",
    "    train.loc[:,'Pclass':],\n",
    "     test.loc[:,'Pclass':]))\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age          263\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           1\n",
       "Cabin       1014\n",
       "Embarked       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PClass (apesar de numérico) -> dummies\n",
    "# Names -> *transformar em títulos* e dummies\n",
    "# Age -> preencher com média por grupos\n",
    "# Sex -> Dummies\n",
    "# SibSp e Parch -> transformar em tamanho da família\n",
    "# Ticket -> Manter só as letras\n",
    "# Fare -> preencher nulos com média\n",
    "# Cabin -> transformar em deck, preencher com moda (U) e dummies\n",
    "# Embarked -> preencher nulos com a moda e depois dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_map = {\n",
    "    'Capt':         'Officer',\n",
    "    'Col':          'Officer',\n",
    "    'Major':        'Officer',\n",
    "    'Jonkheer':     'Royalty',\n",
    "    'Don':          'Royalty',\n",
    "    'Sir' :         'Royalty',\n",
    "    'Dr':           'Officer',\n",
    "    'Rev':          'Officer',\n",
    "    'the Countess': 'Royalty',\n",
    "    'Dona':         'Royalty',\n",
    "    'Mme':          'Mrs',\n",
    "    'Mlle':         'Miss',\n",
    "    'Ms':           'Mrs',\n",
    "    'Mr' :          'Mr',\n",
    "    'Mrs' :         'Mrs',\n",
    "    'Miss' :        'Miss',\n",
    "    'Master' :      'Master',\n",
    "    'Lady' :        'Royalty'\n",
    "}\n",
    "all_data['Title'] = all_data['Name'].map(lambda name: name.split(',')[1].split('.')[0].strip())\n",
    "all_data['Title'] = all_data['Title'].map(title_map)\n",
    "titles_dummies = pd.get_dummies(all_data['Title'], prefix='Title', drop_first=True)\n",
    "all_data = pd.concat([all_data, titles_dummies], axis=1)\n",
    "all_data.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillAges(row):\n",
    "    if row['Sex'] == 'female' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 30\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 45\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 49\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return 39\n",
    "\n",
    "    elif row['Sex'] == 'female' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 20\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 30\n",
    "\n",
    "    elif row['Sex'] == 'female' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 18\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 31\n",
    "\n",
    "    elif row['Sex'] == 'male' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 41.5\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 52\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return 40\n",
    "\n",
    "    elif row['Sex'] == 'male' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 2\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 30\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 41.5\n",
    "\n",
    "    elif row['Sex'] == 'male' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 26\n",
    "all_data['Age'] = all_data.apply(lambda r : fillAges(r) if np.isnan(r['Age']) else r['Age'], axis=1)\n",
    "all_data.drop('Title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Sex'] = all_data['Sex'].map(lambda x: 1 if x == 'male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introducing other features based on the family size\n",
    "all_data['FamilySize']  = all_data['Parch'] + all_data['SibSp'] + 1\n",
    "all_data['Singleton']   = all_data['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
    "all_data['SmallFamily'] = all_data['FamilySize'].map(lambda s : 1 if 2 <= s <= 4 else 0)\n",
    "all_data['LargeFamily'] = all_data['FamilySize'].map(lambda s : 1 if 5 <= s else 0)\n",
    "all_data.drop(['SibSp', 'Parch'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket\n",
       "LP           1\n",
       "SOP          1\n",
       "SCOW         1\n",
       "AS           1\n",
       "SCAHBasle    1\n",
       "Fa           1\n",
       "CASOTON      1\n",
       "STONOQ       1\n",
       "SP           1\n",
       "SC           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['Ticket'] = all_data['Ticket'].map(lambda x: ''.join(filter(str.isalpha, x)))\n",
    "all_data['Ticket'] = all_data['Ticket'].map(lambda x: x if x else 'XXX')\n",
    "tickets_dummies = pd.get_dummies(all_data['Ticket'], prefix='Ticket', drop_first=True)\n",
    "all_data = pd.concat([all_data, tickets_dummies], axis=1)\n",
    "\n",
    "train_unique_tickets = ['CASOTON','SP','Fa','SCOW','SC','SOP','AS','SCAHBasle','FC','SCA']\n",
    "test_unique_tickets = ['LP','SC','WEP','SOTONO','STONOQ','PP','SCParis']\n",
    "all_data['Ticket'].value_counts().sort_values(ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tickets_count = all_data[train.shape[0]:]['Ticket'].value_counts()\n",
    "test_tickets_count = all_data[:train.shape[0]]['Ticket'].value_counts()\n",
    "\n",
    "train_unique_tickets = list(train_tickets_count[train_tickets_count == 1].keys())\n",
    "test_unique_tickets = list(test_tickets_count[test_tickets_count == 1].keys())\n",
    "\n",
    "unique_tickets = [f'Ticket_{ticket}' for ticket in set(train_unique_tickets + test_unique_tickets)]\n",
    "\n",
    "all_data.drop('Ticket', inplace=True, axis=1)\n",
    "all_data.drop(unique_tickets, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_mean = all_data['Fare'].mean()\n",
    "all_data['Fare'] = all_data['Fare'].fillna(fare_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider dropping Cabin column\n",
    "all_data['Cabin'] = all_data['Cabin'].fillna('U')\n",
    "all_data['Cabin'] = all_data['Cabin'].map(lambda x: x[0])\n",
    "cabin_dummies = pd.get_dummies(all_data['Cabin'], prefix='Cabin', drop_first=True)\n",
    "all_data = pd.concat([all_data, cabin_dummies], axis=1)\n",
    "all_data.drop('Cabin', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mode = all_data['Embarked'].mode()\n",
    "all_data['Embarked'] = all_data['Embarked'].fillna(embarked_mode)\n",
    "embarked_dummies = pd.get_dummies(all_data['Embarked'], prefix='Embarked', drop_first=True)\n",
    "all_data = pd.concat([all_data, embarked_dummies], axis=1)\n",
    "all_data.drop('Embarked', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numerical features\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != 'object'].index\n",
    "# calculate skew\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "# only filter skew higher than 0.75\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75].index\n",
    "# normalize with log(1+x)\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(all_data)\n",
    "X = scaler.transform(all_data)\n",
    "all_data = pd.DataFrame(X, columns=all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data[:train.shape[0]]\n",
    "test = all_data[train.shape[0]:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_instances = [\n",
    "#     (RandomForestClassifier(), 'RandomForestClassifier'),\n",
    "#     (ExtraTreesClassifier(), 'ExtraTreesClassifier'),\n",
    "#     (GradientBoostingClassifier(), 'GradientBoostingClassifier'),\n",
    "#     (LogisticRegression(), 'LogisticRegression'),\n",
    "#     (DecisionTreeClassifier(), 'DecisionTreeClassifier'),\n",
    "#     (KNeighborsClassifier(), 'KNeighborsClassifier'),\n",
    "#     (GaussianNB(), 'GaussianNB'),\n",
    "#     (Perceptron(), 'Perceptron'),\n",
    "#     (SGDClassifier(), 'SGDClassifier'),\n",
    "#     (SVC(), 'SVC'),\n",
    "#     (LinearSVC(), 'LinearSVC'),\n",
    "#     (LGBMClassifier(verbose=0), 'LGBMClassifier'),\n",
    "#     (XGBClassifier(), 'XGBClassifier'),\n",
    "#     (CatBoostClassifier(verbose=False), 'CatBoostClassifier'), \n",
    "# ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {\n",
    "#     'Model':[],\n",
    "#     'ACC':[]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model, model_name in model_instances:\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     results['Model'].append(model_name)\n",
    "#     results['ACC'].append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame(results)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_temp = results.sort_values('ACC', ascending=False)\n",
    "# results_temp.iloc[:5]['Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instances = [\n",
    "    (LogisticRegression(**{'penalty': 'l2', 'solver': 'liblinear', 'C':0.2}), 'LogisticRegression'),\n",
    "    (SVC(**{'C': 5, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'}), 'SVC'),\n",
    "    (XGBClassifier(**{'eta':0.1, 'gamma':0, 'max_depth':6, 'lambda':0.1, 'alpha':10}), 'XGBClassifier'),\n",
    "    (CatBoostClassifier(**{'rsm':0.1, 'learning_rate':0.005, 'iterations':500, 'l2_leaf_reg':5, 'verbose':False}), 'CatBoostClassifier')\n",
    "] \n",
    "\n",
    "results = {\n",
    "    'Model':[],\n",
    "    'ACC':[]\n",
    "}\n",
    "\n",
    "for model, model_name in model_instances:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results['Model'].append(model_name)\n",
    "    results['ACC'].append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.811659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.834081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.825112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.829596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model       ACC\n",
       "0  LogisticRegression  0.811659\n",
       "1                 SVC  0.834081\n",
       "2       XGBClassifier  0.825112\n",
       "3  CatBoostClassifier  0.829596"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(**{'C': 5, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'})\n",
    "xgb = XGBClassifier(**{'eta': 0.1, 'gamma': 0, 'max_depth':6, 'lambda': 0.1, 'alpha': 10})\n",
    "cat = CatBoostClassifier(**{'rsm': 0.1, 'learning_rate': 0.005, 'iterations': 500, 'l2_leaf_reg': 5, 'verbose': False})\n",
    "lor = LogisticRegression(**{'penalty': 'l2', 'solver': 'liblinear', 'C': 0.2})\n",
    "\n",
    "stack_gen=StackingClassifier(\n",
    "    classifiers=(svc, xgb, cat, lor),\n",
    "    meta_classifier=LogisticRegression(**{'penalty': 'l2', 'solver': 'liblinear', 'C': 0.2}),\n",
    "    use_features_in_secondary=True)\n",
    "\n",
    "stack_gen.fit(X.values, y.values)\n",
    "prediction = stack_gen.predict(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Escolha dos melhores parâmetros\n",
    "# randomForest = RandomForestClassifier()\n",
    "# cross_validation = StratifiedKFold(n_splits=5) # n_folds deve ser escolhido de forma precisa\n",
    "# parameter_grid = {\n",
    "#                  'max_depth' : [18,19],\n",
    "#                  'n_estimators': [1000,2000,3000],\n",
    "#                  'criterion': ['gini','entropy',]\n",
    "#                  }\n",
    "# grid_search = GridSearchCV(randomForest,param_grid=parameter_grid,cv=cross_validation)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print('Best score: {}'.format(grid_search.best_score_))\n",
    "# print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest = RandomForestClassifier(\n",
    "#     n_estimators=10000, # tunado\n",
    "#     criterion='entropy', # tunado\n",
    "#     max_depth=15, # tunado\n",
    "#     min_samples_split=27, # tunado\n",
    "#     max_features=8)\n",
    "\n",
    "# random_forest.fit(X, y)\n",
    "# y_pred = random_forest.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv', index_col=0)\n",
    "sample_submission['Survived'] = prediction\n",
    "sample_submission.to_csv('stack_tunado.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
